{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12471997,"sourceType":"datasetVersion","datasetId":7868514},{"sourceId":474455,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":381829,"modelId":401432}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install dependencies","metadata":{}},{"cell_type":"code","source":"!pip install transformers datasets torch scikit-learn evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T10:46:47.723112Z","iopub.execute_input":"2025-07-16T10:46:47.723565Z","iopub.status.idle":"2025-07-16T10:48:09.833064Z","shell.execute_reply.started":"2025-07-16T10:46:47.723543Z","shell.execute_reply":"2025-07-16T10:48:09.832374Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nCollecting evaluate\n  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, evaluate\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.5.1\n    Uninstalling fsspec-2025.5.1:\n      Successfully uninstalled fsspec-2025.5.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.5 fsspec-2025.3.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom transformers import get_linear_schedule_with_warmup\nfrom torch.optim import AdamW\nfrom datasets import Dataset\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import accuracy_score, f1_score\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport random\nimport os\ndef set_seed(seed=42):\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nset_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T10:49:11.290517Z","iopub.execute_input":"2025-07-16T10:49:11.291007Z","iopub.status.idle":"2025-07-16T10:49:11.297578Z","shell.execute_reply.started":"2025-07-16T10:49:11.290984Z","shell.execute_reply":"2025-07-16T10:49:11.297010Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/ai-text/ai_press_releases.csv')\ndf=df.dropna()\nhuman=df['non_chat_gpt_press_release'].to_list()\nai=df['chat_gpt_generated_release'].to_list()\nlabels=[0 if i<len(ai) else 1 for i in range(len(ai)+len(human))]\nai.extend(human)\ntexts=ai\n# 1) 먼저 train_temp(80%)와 test(20%) 분할\ntexts_train_val, texts_test, labels_train_val, labels_test = train_test_split(\n    texts,\n    labels,\n    test_size=0.2,       # 전체의 20%\n    random_state=42,\n    stratify=labels      # 레이블 비율 유지\n)\n\n# 2) train_temp을 다시 train(75% of temp → 60% 전체)와 val(25% of temp → 20% 전체)로 분할\ntexts_train, texts_val, labels_train, labels_val = train_test_split(\n    texts_train_val,\n    labels_train_val,\n    test_size=0.25,      # train_temp의 25% → 전체의 0.2\n    random_state=42,\n    stratify=labels_train_val\n)\n\nprint(f\"Train: {len(texts_train)} samples\")\nprint(f\"Valid: {len(texts_val)} samples\")\nprint(f\"Test : {len(texts_test)} samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T10:49:13.270881Z","iopub.execute_input":"2025-07-16T10:49:13.271521Z","iopub.status.idle":"2025-07-16T10:49:15.497292Z","shell.execute_reply.started":"2025-07-16T10:49:13.271495Z","shell.execute_reply":"2025-07-16T10:49:15.496622Z"}},"outputs":[{"name":"stdout","text":"Train: 13898 samples\nValid: 4633 samples\nTest : 4633 samples\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Load Model","metadata":{}},{"cell_type":"code","source":"# 2. Sentence split\ndef split_sentences(paragraph: str):\n    return [s.strip() for s in paragraph.split('. ') if s.strip()]\n\n# 3. Dataset\nclass ParagraphDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_sents=16, max_len=128):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_sents = max_sents\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, i):\n        para = self.texts[i]\n        label = torch.tensor(self.labels[i], dtype=torch.float)\n        sents = split_sentences(para)[:self.max_sents]\n        encs = [self.tokenizer(s, truncation=True, padding='max_length',\n                               max_length=self.max_len, return_tensors='pt')\n                for s in sents]\n        # pad sentences\n        pad_n = self.max_sents - len(encs)\n        input_ids = torch.stack([e['input_ids'].squeeze(0) for e in encs] +\n                                [torch.zeros(self.max_len, dtype=torch.long)]*pad_n)\n        attn_mask = torch.stack([e['attention_mask'].squeeze(0) for e in encs] +\n                                [torch.zeros(self.max_len, dtype=torch.long)]*pad_n)\n        return input_ids, attn_mask, label\n\n# 4. Model: frozen encoder + attention + classifier\nimport torch\nimport torch.nn as nn\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\nclass HierAttnClassifier(nn.Module):\n    def __init__(self,\n                 base_model_name=\"/kaggle/input/robertector/transformers/sentences/1/checkpoint-epoch3\",\n                 max_sents=16,\n                 hidden=768,\n                 heads=4):\n        super().__init__()\n        # 1) Load your fine‑tuned SequenceClassification model\n        self.full_model = AutoModelForSequenceClassification.from_pretrained(\n            base_model_name, output_hidden_states=True, return_dict=True\n        )\n        # 2) Freeze all its parameters\n        for p in self.full_model.parameters():\n            p.requires_grad = False\n\n        # 3) Multi‑Head Attention on the CLS embeddings\n        self.attn = nn.MultiheadAttention(embed_dim=hidden,\n                                          num_heads=heads,\n                                          batch_first=True)\n        # 4) Final MLP head after attention\n        self.classifier = nn.Sequential(\n            nn.Linear(hidden, hidden // 2),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(hidden // 2, 1),\n        )\n\n    def forward(self, input_ids, attention_mask):\n        b, s, l = input_ids.size()\n        # flatten to (b*s, l)\n        flat_ids   = input_ids.view(b * s, l)\n        flat_mask  = attention_mask.view(b * s, l)\n        # 5) Run through RoBERTector; we asked for hidden_states\n        outputs = self.full_model(\n            input_ids=flat_ids,\n            attention_mask=flat_mask,\n        )\n        # 6) Grab the last hidden layer states: outputs.hidden_states is a tuple\n        #    where hidden_states[-1] is (batch, seq_len, hidden)\n        last_hid = outputs.hidden_states[-1]        \n        # CLS is token 0\n        cls_embs = last_hid[:, 0, :].view(b, s, -1)  # (b, s, hidden)\n\n        # 7) Self‑attention over the s sentence embeddings\n        attn_out, _ = self.attn(cls_embs, cls_embs, cls_embs)  # (b, s, hidden)\n\n        # 8) Pool and classify\n        doc_emb = attn_out.mean(dim=1)                       # (b, hidden)\n        logits = self.classifier(doc_emb).squeeze(-1)        # (b,)\n        return logits\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T10:50:06.187494Z","iopub.execute_input":"2025-07-16T10:50:06.188228Z","iopub.status.idle":"2025-07-16T10:50:06.207641Z","shell.execute_reply.started":"2025-07-16T10:50:06.188196Z","shell.execute_reply":"2025-07-16T10:50:06.206963Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# 5. Prepare data, loaders, model, optimizer\nmodel_path = \"/kaggle/input/robertector/transformers/sentences/1/checkpoint-epoch3\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load the tokenizer from the directory\n# This reads files like tokenizer.json and tokenizer_config.json\ntokenizer = AutoTokenizer.from_pretrained(model_path)\n\n# Load the model from the directory\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path).to(device)\ndataset = ParagraphDataset(texts, labels, tokenizer)\nn = len(dataset)\n\ntrain_n = int(0.6*n); val_n = int(0.2*n); test_n = n - train_n - val_n\ntrain_ds, val_ds, test_ds = random_split(dataset, [train_n, val_n, test_n])\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=2)\nval_loader   = DataLoader(val_ds, batch_size=64, num_workers=2)\ntest_loader  = DataLoader(test_ds, batch_size=64, num_workers=2)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = HierAttnClassifier().to(device)\nopt = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\ncriterion = nn.BCEWithLogitsLoss()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T10:54:16.745017Z","iopub.execute_input":"2025-07-16T10:54:16.745861Z","iopub.status.idle":"2025-07-16T10:54:17.460128Z","shell.execute_reply.started":"2025-07-16T10:54:16.745831Z","shell.execute_reply":"2025-07-16T10:54:17.459366Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\nnum_epochs = 6\nos.makedirs('/kaggle/working/ckpts', exist_ok=True)\n\nfor epoch in range(1, num_epochs + 1):\n    # ── TRAIN ───────────────────────────────────────────────\n    model.train()\n    train_loss_sum = 0.0\n    train_steps    = 0\n    loop = tqdm(train_loader, desc=f\"Train E{epoch}\")\n    for ids, mask, lbl in loop:\n        ids, mask, lbl = ids.to(device), mask.to(device), lbl.to(device)\n        opt.zero_grad()\n        logits = model(ids, mask)\n        loss   = criterion(logits, lbl)\n        loss.backward()\n        opt.step()\n\n        train_loss_sum += loss.item()\n        train_steps    += 1\n        # tqdm 바에 현재 배치 손실 표시\n        loop.set_postfix(loss=f\"{loss.item():.4f}\")\n\n    avg_train_loss = train_loss_sum / train_steps\n    print(f\"Epoch {epoch} | Train Loss: {avg_train_loss:.4f}\")\n\n    # ── VALIDATION ─────────────────────────────────────────\n    model.eval()\n    val_loss_sum = 0.0\n    preds, trues = [], []\n    with torch.no_grad():\n        for ids, mask, lbl in val_loader:\n            ids, mask, lbl = ids.to(device), mask.to(device), lbl.to(device)\n            logits = model(ids, mask)\n            loss   = criterion(logits, lbl)\n            val_loss_sum += loss.item()\n            preds += (torch.sigmoid(logits) > 0.5).cpu().int().tolist()\n            trues += lbl.cpu().int().tolist()\n    avg_val_loss = val_loss_sum / len(val_loader)\n    acc = accuracy_score(trues, preds)\n    f1  = f1_score(trues, preds)\n    print(f\"Epoch {epoch} | Val Loss: {avg_val_loss:.4f} | Acc: {acc:.4f} | F1: {f1:.4f}\")\n\n    # ── CHECKPOINT SAVE ────────────────────────────────────\n    checkpoint_path = f\"/kaggle/working/ckpts/epoch{epoch}.pt\"\n    torch.save(model.state_dict(), checkpoint_path)\n    print(f\"Saved checkpoint: {checkpoint_path}\")\n\n# ── FINAL TEST ────────────────────────────────────────────\nmodel.load_state_dict(torch.load('/kaggle/working/ckpts/epoch6.pt'))\nmodel.eval()\npreds, trues = [], []\nwith torch.no_grad():\n    for ids, mask, lbl in test_loader:\n        ids, mask, lbl = ids.to(device), mask.to(device), lbl.to(device)\n        logits = model(ids, mask)\n        preds += (torch.sigmoid(logits) > 0.5).cpu().int().tolist()\n        trues += lbl.cpu().int().tolist()\nacc = accuracy_score(trues, preds)\nf1  = f1_score(trues, preds)\nprint(f\"Test Acc {acc:.4f} | F1 {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T11:00:57.523503Z","iopub.execute_input":"2025-07-16T11:00:57.524298Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Train E1:   0%|          | 0/218 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b89cd14b47c04084ac95bb4d5de01788"}},"metadata":{}},{"name":"stdout","text":"Epoch 1 | Train Loss: 0.0283\nEpoch 1 | Val Loss: 0.0388 | Acc: 0.9877 | F1: 0.9877\nSaved checkpoint: /kaggle/working/ckpts/epoch1.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train E2:   0%|          | 0/218 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"994909c1dbed41558f90d1acf0e8e47f"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e71bb927a60>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e71bb927a60>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e71bb927a60>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e71bb927a60>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# 3) Obtain attention weights for a sample paragraph\nparagraph = \"Enter your paragraph here. It can be several sentences. The model will attend to each.\"\ncls_embs, sentences = get_sentence_embeddings(paragraph)\nwith torch.no_grad():\n    doc_emb, attn_weights = model(cls_embs)\n\n# 4) Plot attention heatmap\nweights = attn_weights[0].cpu().numpy()  # shape (n_sent, n_sent)\nplt.figure(figsize=(6,6))\nplt.imshow(weights, aspect='auto')\nplt.xlabel('Key Sentence Index')\nplt.ylabel('Query Sentence Index')\nplt.title('Hierarchical Attention Weights')\nplt.colorbar()\nplt.xticks(range(len(sentences)), range(len(sentences)))\nplt.yticks(range(len(sentences)), range(len(sentences)))\nplt.show()\n\n# 5) Sentence importance scores (mean over queries)\nimportance = weights.mean(axis=0)\ntop_idx = importance.argsort()[-3:][::-1]\nprint(\"Top 3 important sentences:\")\nfor idx in top_idx:\n    print(f\"{idx}: {sentences[idx]}\")\n\n# 6) t-SNE visualization of document embeddings (multiple paragraphs example)\n# Suppose you have a list of paragraphs: docs = [p1, p2, ...]\n# Here we illustrate with a small list\ndocs = [paragraph, \"Another example paragraph. It has different style.\"]  # replace with your test set\nembs = []\nlabels = [0,1]  # example labels: 0=human,1=AI\nfor p in docs:\n    cls_embs, _ = get_sentence_embeddings(p)\n    with torch.no_grad():\n        doc_emb, _ = model(cls_embs)\n    embs.append(doc_emb.cpu().numpy().squeeze())\nembs = torch.tensor(embs).numpy()\ntsne = TSNE(n_components=2, random_state=42)\nproj = tsne.fit_transform(embs)\nplt.figure()\nplt.scatter(proj[:,0], proj[:,1])\nfor i, label in enumerate(labels):\n    plt.annotate(str(label), (proj[i,0], proj[i,1]))\nplt.title('t-SNE of Document Embeddings')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T09:42:23.211239Z","iopub.execute_input":"2025-07-16T09:42:23.211595Z","iopub.status.idle":"2025-07-16T09:42:23.256390Z","shell.execute_reply.started":"2025-07-16T09:42:23.211570Z","shell.execute_reply":"2025-07-16T09:42:23.254326Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1946811501.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 3) Obtain attention weights for a sample paragraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mparagraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Enter your paragraph here. It can be several sentences. The model will attend to each.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcls_embs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sentence_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdoc_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_embs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'get_sentence_embeddings' is not defined"],"ename":"NameError","evalue":"name 'get_sentence_embeddings' is not defined","output_type":"error"}],"execution_count":13}]}